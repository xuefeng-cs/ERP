seed_random: 42
algorithm: mcts # [bs, mcts, mcts_multi]
horizon: 90 # The maximum number of tokens to generate.
mol_metric:
  metric_name: sdad # ["logp", "sdad"]  # sdad : Solubility, Druglikeness, Synthetic accessibility, and Docking score
  docking_dataset: cancer # [null, "cancer", "covid"] Not applicable if mol_metric is "logp"
  normalization: true # [true, false]
  invalid_values: [0.0, 0.0, 0.0, 0.0] # Not applicable if mol_metric is "logp"

heuristic: # the heuristic default policy of MCTS
  horizon: ${horizon} # The maximum number of tokens to generate.

  # Expansion # TODO : Sample in expansion?
  top_k_expansion: 20 # 0 means no limit
  top_p_expansion: 0.95 # 1.0 means no limit
  top_k_uniform: false

  # Simulation / Evaluation
  generation_mode: best # ["best", "sample"] Within the evaluation step, `best` uses beam search, `sample` uses sampling.
  num_beams: 16 # The number of beams for beam search or PG-TD.
  test_all_beams: true # If True, will run all the beams on test cases to find the best program, which is more time-consuming;
  value_model: null
  use_reward_estimate_cache: true

  # in general, for both expansion and simulation.
  generation_config:
    use_cache: true
    renormalize_logits: true

  # use_seq_cache: false # TOOD: probably not implmented; but may experiment with it
  debug: false

ts: # Tree search
  uct:
    rollouts: 256 # 2048; 256 seems nice.
    horizon: ${horizon}
    # ts_mode: ${ts_mode}

    # Selection
    alg: p_ucb # ["ucb", "p_ucb", "pb_ucb", "var_p_ucb"]
    selection: max # ["max", "random"]
    exploitation_mode: best # ["best", "average"]
    exploration_mode: pgtd # ["pgtd", "dynagym"]
    exploration_denominator_summand: 1.0
    ucb_constant: 4.0 # 4 or 6.36396103068 or 1 or else
    ucb_base: 10.0 # 10 or 50 or else, only useful when alg is "var_p_ucb"
    entropy_combining_mode: null # ["mul", "add", null]
    entropy_entering_mode: null # ["div", "mul", null]
    entropy_forward_k: 0 # non-negative integer, only effective when entropy_combining_mode is not null
    entropy_k_averaging: true # only effective when entropy_combining_mode is not null
    entropy_prob_smoother: null # null or float. null is equivalent to 0.0. To avoid inf when entering_mode=div.  non-negative float, only effective when entropy_combining_mode is not null
    entropy_alpha: 1.0 # non-negative float
    reward_estimate_combining_mode: null # ["mul", "add", null]
    reward_estimate_weight: 1.0 # non-negative float

  horizon: ${horizon}
  max_sample_times: 4096 # The maximum number of Transformer generation function calls. Program stops when this number is reached (default to be 512 * 1.5 = 768).
  time_limit: 100000 # "Time limit in sec. Program stops when time limit is reached."
  entropy_weighted_strategy: none
  debug: false

sample:
  rollouts: 256
  horizon: ${horizon}
  temperature: 1.0
  top_k: 20
  top_p: 0.95

bs: # Beam search
  horizon: ${horizon}

nn:
  checkpoint: null
  # [jarod0411/zinc10M_gpt2_SMILES_bpe_combined_step1,  # only pretrained

  #  jarod0411/zinc10M_gpt2_SMILES_bpe_combined_step1_finetune, # for cancer
  #  jarod0411/zinc10M_gpt2_SMILES_bpe_combined_step1_rl_finetune_cancer_b16,
  #  jarod0411/zinc10M_gpt2_SMILES_bpe_combined_step1_rl_finetune_cancer_b64,

  #  jarod0411/zinc10M_gpt2_SMILES_bpe_combined_step1_finetune_covid, # for covid
  #  jarod0411/zinc10M_gpt2_SMILES_bpe_combined_step1_rl_finetune_covid_b16,
  #  jarod0411/zinc10M_gpt2_SMILES_bpe_combined_step1_rl_finetune_covid_b64,
  # ]
  use_cpu: false

hydra:
  job:
    chdir: false
    name: search_${algorithm}
  verbose: false
